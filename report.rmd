---
title: "IB031 Mice Protein Expression"
author: "Vladimír Bača"
date: "May 23, 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, echo=FALSE, message=FALSE}
library(corrplot)
library(VIM)
library(keras)
library(readr)

set.seed(9)
```

## Dataset

Vybraný dataset Mice Protein Expression (https://archive.ics.uci.edu/ml/datasets/Mice+Protein+Expression) obsahuje úrovne expresie proteínov v mozgoch myší, ktoré sú z 8 rôznych kontrolných skupín. Kontrolná skupina je kombinácia 3 binárnych atribútov: Genotyp (S/Bez Downovho syndrómu), Liek (Memantine/Bez lieku) a Stimulácia (S/Bez). Úlohou bude naučiť model určiť kontrolnú skupinu na základe expresií proteínov.

## Exploračná analýza

Prvý stĺpec datasetu (MouseID) obsahuje ID myší a nebude pre nás relevantný. Stĺpce 2 - 78 obsahujú expresie jednotlivých proteínov a budú predstavovať vstupné dáta. Stĺpce 79 - 81 (Genotype, Treatment, Behavior) sú binárne atribúty, ktoré určujú danú kontrolnú skupinu a budú pre nás výstupom. Posledný stĺpec (class) obsahuje už len reťazec kombinujúci predchádzajúce tri stĺpce. Spolu teda máme 77 vstupných atribútov (kladné reálne čísla) a 3 výstupné binárne atribúty. Dataset obsahuje 1080 inštancií.

```{r dataset}

data <- read.csv(file="dataset.csv", header=TRUE, sep=",")
str(data)

```

```{r missing}
missing_values_count <- length(data[is.na(data)])
missing_values_ratio <- missing_values_count / (77*nrow(data))
missing_values_count
missing_values_ratio

```

Niektoré vstupné hodnoty chýbajú (1396, t.j. 1,7% chýbajúcich hodnôt).

Vykreslíme si korelačnú maticu vstupných atribútov (zgrupené sú atribúty so silnou koreláciou, chýbajúce dáta sú imputované).

```{r corr}

imputedData <- kNN(data[, 2:78], k=5, imp_var = FALSE)
corMat <- cor(imputedData)
corrplot(corMat, order = "hclust", tl.pos = FALSE)

```

Ako vidíme, medzi proteínmi existuje niekoľko skupín, ktorých expresia spolu výrazne koreluje. Mohlo by teda byť zaujímavé vyskúšať feature extraction.

Pozrieme sa tiež na distribúciu výstupných tried.

```{r distribution}

table(data[, 79:81])

```

Ako vidíme, triedy sú pomerne rovnomerne distribuované. Z distribúcie tiež možno vyčítať naivný baseline odhad. Tým by bol klasifikátor vyberajúci najpočetnejšiu triedu, t.j. napr. Control-Memantine-C/S. Jeho accuracy by bola 150/1080 = 13,9%.

## Predspracovanie

Nakoľko dáta sú zoradené podľa kontrolných skupín, na začiatok ich náhodne zamiešame. Potom ich rozdelíme na 80% trénovaciu a 20% testovaciu množinu.

```{r division}

data <- data[sample(nrow(data)),]
data_train <- data[1:round(nrow(data)*0.8),]
data_test <- data[(round(nrow(data)*0.8)+1):nrow(data),]

```

Chýbajúce dáta v trénovacej množine imputujeme pomocou metódy kNN. V testovacej množine chýbajúce hodnoty len nahradíme nulou.

```{r imputation}

data_train <- kNN(data_train, k=5, imp_var = FALSE)

data_test[is.na(data_test)] <- 0

```

Pre spracovanie neurónovou sieťou potrebujeme dáta rozdeliť na maticu vstupov a maticu výstupov. Vstupné hodnoty sú kladné reálne čísla, preto ich len vložíme do matice. Výstupná trieda je zložená z troch binárnych atribútov, transformujeme ju teda na vektor troch čísel 0/1. Neurónová sieť potom bude mať vo výstupnej vrstve tri neuróny, ktoré budeme trénovať na hodnoty 0 alebo 1 podľa konkrétnej triedy.

```{r preparation}
train_x <- as.matrix(data_train[, 2:78])

genotype <- ifelse(data_train$Genotype == "Control", 0, 1)
treatment <- ifelse(data_train$Treatment == "Memantine", 1, 0)
behaviour <- ifelse(data_train$Behavior == "C/S", 1, 0)

train_y <- matrix(c(genotype, treatment, behaviour), ncol = 3, byrow = FALSE)

test_x <- as.matrix(data_test[, 2:78])

genotype <- ifelse(data_test$Genotype == "Control", 0, 1)
treatment <- ifelse(data_test$Treatment == "Memantine", 1, 0)
behaviour <- ifelse(data_test$Behavior == "C/S", 1, 0)

test_y <- matrix(c(genotype, treatment, behaviour), ncol = 3, byrow = FALSE)
```

## Multi-layer perceptron
ML model našej skupiny je multi-layer perceptron, teda viacvrstvová neurónová sieť. Táto je zložená z jednotlivých neurónov. Neurón je jednoduchá výpočtová jednotka, inšpirovaná biologickými neurónmi, ktorá má vektor reálnych vstupov a jeden reálny výstup. Výpočet prebieha tak, že jednotlivé vstupy sú najprv vynásobené váhami a potom sčítané. Na výsledok sa aplikuje aktivačná funkcia, typicky sigmoida a jej výstup sa pošle ďalej. V viacvrstvovej sieti je niekoľko takýchto neurónov usporiadaných do vrstiev. Spodná vrstva pritom tvorí vstup celej siete a vrchná jej výstup. Každý neurón (okrem tých vo vstupnej vrstve) má za vstup výstupy všetkých neurónov vo vrstve pod ním.

Učenie v tomto modeli má za cieľ nastaviť váhy jednotlivých spojení tak, aby výstup siete na vzorových vstupoch bol čo najbližšie cieľovým výstupom. Prebieha tak, že sieť spracuje danú dávku vstupov a jej výstupy sa porovnajú s požadovanými výstupmi. Rozdiel medzi požadovaným a reálnym výstupom tvorí chybovú funkciu. Na túto sa môžeme pozerať ako na funkciu vektora všetkých váh, ktorú vieme derivovať. Preto ju môžeme optimalizovať pomocou gradientného zostupu. Tento postup iteratívne opakujeme, kým sa sieť zlepšuje (a nepreučuje).

### Výber modelu
V našom prípade pre neurónové siete použijeme R balíček keras.

Neurónová sieť bude mať 77 vstupov (77 vstupných atribútov z datasetu). Výstupná vrstva bude mať 3 neuróny, každý bude predstavovať jeden binárny výstupný atribút (0 pre jednu možnosť, 1 pre druhú). Po niekoľkých experimentoch sa ako vhodné ukázali 2 skryté vrstvy. Pre 1 vrstvu bola accuracy výrazne nižšia, 3 vrstvy naopak už na accuracy nepridávali. Ako aktivačná funkcia bola použitá sigmoida, s výnimkou výstupnej vrstvy, kde bola použitá hard_sigmoid. Dôvodom je, že cieľovým výstupom je vždy buď 0 alebo 1, hodnoty medzi nimi len zaokrúhlime. Tento výber mal lepšie výsledky než sigmoida.

Najlepšou nájdenou architektúrou bola sieť so 77-20-10-3 neurónmi. Stratová funkcia bola mse, metrika accuracy.

```{r network}
model <- keras_model_sequential()
model %>% 
  layer_dense(units = 20, activation = "sigmoid", input_shape = c(77)) %>% 
  layer_dense(units = 10, activation = "sigmoid") %>% 
  layer_dense(units = 3, activation = "hard_sigmoid")

model %>% compile(
  loss = 'mse',
  metrics = 'accuracy',
  optimizer = 'rmsprop'
)

summary(model)
```

###Tréning

Túto sieť natrénujeme na trénovacej množine.

```{r training, message=FALSE, cache=TRUE}
history <- model %>% fit(
  epochs = 800, batch_size = 10,
  x = train_x, y = train_y, validation_split = 0.1
)

plot(history)
```

Výslednú sieť otestujeme na testovacej množine. Keďže ide o klasifikačnú úlohu, ako metriku použijeme accuracy, t.j. podiel správne klasifikovaných inštancií (pre všetky tri atribúty) a všetkých testovaných inštancií. Nakoľko výsledný vektor z neurónovej siete treba zaokrúhliť, počítanie výslednej accuracy je mierne nemotorné.

```{r evaluation}
prediction <- predict(model, x = test_x)
prediction <- round(prediction)

diffs <- rowSums(abs(test_y - prediction))

test_accuracy <- length(diffs[diffs == 0])/length(diffs)
test_accuracy
```

Výsledná accuracy sa pohybuje (v závislosti od náhodných faktorov) medzi 95 - 98%, čo je veľmi dobrý výsledok (neporovnateľný s naivným odhadom 13,9%).

## Morphological analysis on FastText word embeddings

Nasleduje použitie uvedeného modelu na datasete slov a ich morfologických štítkov od kolegu Adama Bajgera. Potrebné sú súbory final_labels_for_R a word_vectors_for_R.

```{r fasttext, include=FALSE}
word_labels  <- data.matrix (
  read_tsv("final_labels_for_R", col_names=FALSE, col_types=cols(.default = "i")))
word_vectors <- data.matrix (
  read_tsv("word_vectors_for_R", col_names=FALSE, col_types=cols(.default = "d")))

dimnames(word_labels) <- NULL
dimnames(word_vectors) <- NULL

# 75% of the sample size
smp_size <- floor(0.75 * nrow(word_labels))

# set the seed to make your partition reproducible
set.seed(247)
train_ind <- sample(seq_len(nrow(word_labels)), size = smp_size)

train_word_labels <- word_labels[train_ind, ]
test_word_labels <- word_labels[-train_ind, ]

train_word_vectors <- word_vectors[train_ind, ]
test_word_vectors <- word_vectors[-train_ind, ]
```

Aby sme mohli použiť moju neurónovú sieť na týchto dátach, je nutné upraviť vstupnú a výstupnú vrstvu. Výsledkom je pomerne bizarná kombinácia našich dvoch sietí.

```{r fnetwork}
nn <- keras_model_sequential()
nn %>% 
  layer_dense(units = 20, activation = "sigmoid", input_shape = c(100)) %>% 
  layer_dense(units = 10, activation = "sigmoid") %>% 
  layer_dense(units = 12, activation = 'hard_sigmoid') 

summary(nn)

nn %>% 
  compile(
    loss = 'mse',
    metrics = 'accuracy',
    optimizer = 'rmsprop'
  )
```

Sieť natrénujeme.

```{r ftraining, message=FALSE, cache=TRUE}

f_history <- nn %>% fit(
  train_word_vectors, train_word_labels, 
  epochs = 10, batch_size = 10, validation_split = 0.1
)

plot(f_history)
```

Vyhodnotíme accuracy.

```{r fevaluation, message=FALSE, cache=TRUE}

nn %>% evaluate(test_word_vectors, test_word_labels)

```

Výsledná accuracy je okolo 83%. To je prekvapivo dobrý výsledok, vzhľadom k veľkosti druhého datasetu a k tomu, že sieť je približne 10x menšia, než pôvodná sieť pre druhý dataset.